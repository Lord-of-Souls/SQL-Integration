# Advanced Data Integration & Marketing Strategy

## Description
This project focuses on the intersection of data engineering and inferential statistics. It demonstrates the ability to manage complex data structures—combining relational databases (SQL) with semi-structured formats (JSON)—to identify product vulnerabilities and validate strategic marketing shifts through hypothesis testing.

## Project's Objective
The goal is to leverage multi-source data to diagnose product issues, verify these findings using rigorous statistical frameworks, and translate the results into a data-driven advertising campaign.

## Results
- **Root Cause Analysis:** Identified specific product defects and user pain points within the dataset.
- **Statistical Validation:** Successfully confirmed or rejected business assumptions with documented P-values.
- **Strategic Roadmap:** A complete advertising campaign plan optimized for the most profitable and reliable customer segments.
- **Interoperable Data Layer:** Seamless integration between SQL-based transactional data and JSON-based event logs.

## Methodology
The workflow follows modern 2026 data integration standards:
1.  **Data Ingestion:** Extracting structured data from **SQL** databases and parsing nested **JSON** payloads.
2.  **Product Diagnosis:** Using aggregations and filters to flag anomalies in product performance or user behavior.
3.  **Hypothesis Testing:** Formulating Null ($H_0$) and Alternative ($H_a$) hypotheses to test the impact of specific variables on customer engagement.
4.  **Campaign Architecture:** Utilizing validated insights to select target audiences, messaging, and budget allocation for a new advertising push.

## Utilized Tools
- **Databases:** [SQL](https://www.mysql.com) (Relational querying) & [JSON](https://www.json.org) (Data interchange).
- **Languages:** [Python](https://www.python.org) for automation and integration.
- **Libraries:** [Pandas](https://pandas.pydata.org) (Data processing), [SciPy](https://scipy.org) (Statistical testing), [SQLAlchemy](https://www.sqlalchemy.org) (Database connection).
- **Visualization:** [Seaborn](https://seaborn.pydata.org) & [Matplotlib](https://matplotlib.org).

## Acquired/Developed Abilities
- **Schema Management:** Handling data across different storage paradigms (Structured vs. Semi-structured).
- **Statistical Rigor:** Moving from descriptive analytics to inferential testing to ensure results are not due to random chance.
- **Product Management:** Identifying actionable "bugs" or "features" through quantitative evidence.
- **Strategic Planning:** Bridging the gap between raw data analysis and high-level marketing execution.

## Upgrades to be Made
- [ ] Implement a **NoSQL** bridge (e.g., MongoDB) for more scalable JSON handling.
- [ ] Add **A/B Testing** simulation modules to pre-validate the planned campaign.
- [ ] Develop an automated dashboard to track campaign KPIs in real-time.

## How to Run It
You can run the project files in two ways:

### Option 1: Google Colab
1. Upload the `.ipynb` files directly to [Google Colab](https://colab.research.google.com).
2. Run the cells sequentially.

### Option 2: Local Environment (VS Code)
1. Ensure you have [Python](https://www.python.orgdownloads/) installed.
2. Install the **Jupyter Extension** in VS Code.
3. Open the `.ipynb` file and select your Python interpreter.

---
## Contact & Contribution
If you want to contribute or have any questions, feel free to reach out:
- [**GitHub:**](https://github.com/Lord-of-Souls)
- [**Linkedin:**](www.linkedin.com/in/lucasfranciscon)
